{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries."
      ],
      "metadata": {
        "id": "Mgy1LJKBz-w6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoA0UZivVtBQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "from io import StringIO\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Datasets"
      ],
      "metadata": {
        "id": "XMQbwJoY4mgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Creating the format of the labled dataset & preprocess DrugBank data.**  \n",
        "Please remember that this code will not produce the full dataset used in the paper, as we manually annotated the mechanisms of action of the drugs, Drug_Descriptions and ATC classes . <br>\n",
        "You can find the labled data set in this repository named 'SupplementaryFile_DrugAnnotations_4-05-2024.xlsx'"
      ],
      "metadata": {
        "id": "BT6Qr5oU4DHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_drugBank = pd.read_csv('approved_all_drug_target.csv') # Change the name/path as needed.\n",
        "\n",
        "# Filter out rows where 'Species' column is not 'Humans'\n",
        "df_drugBank = df_drugBank[df_drugBank['Species'] == 'Humans']\n",
        "\n",
        "# Split the values in the \"Drug IDs\" column by \";\"\n",
        "df_drugBank['Drug IDs'] = df_drugBank['Drug IDs'].apply(lambda x: x.split(\"; \"))\n",
        "\n",
        "# Explode the \"Drug IDs\" column so that each value is in a new row\n",
        "df_drugBank = df_drugBank.explode('Drug IDs')\n",
        "\n",
        "# Fill in missing 'Gene Name' values from the 'Name' column and upcase both 'Gene Name' and 'Name'\n",
        "# Convert genes name to uppercase for consistency\n",
        "df_drugBank['Gene Name'] = df_drugBank['Gene Name'].fillna(df_drugBank['Name']).str.upper()\n",
        "df_drugBank['Name'] = df_drugBank['Name'].str.upper()\n",
        "\n",
        "# Export the final DataFrame to a CSV file\n",
        "df_drugBank.to_csv('temp.csv', index=False)\n",
        "\n",
        "# Group by the Drug ID and aggregate the gene names into a list for each drug\n",
        "df_drugBank_grouped = df_drugBank.groupby('Drug IDs')['Gene Name'].apply(list).reset_index()\n",
        "\n",
        "# Find the maximum number of genes associated with any drug\n",
        "num_max_genes = df_drugBank_grouped['Gene Name'].str.len().max()\n",
        "\n",
        "# Padding the gene lists so that each list has the same length\n",
        "df_drugBank_grouped['Gene Name'] = df_drugBank_grouped['Gene Name'].apply(lambda x: x + [None] * (num_max_genes - len(x)))\n",
        "\n",
        "# Convert them into a DataFrame\n",
        "df_genes = pd.DataFrame(df_drugBank_grouped['Gene Name'].to_list(), columns=[f'gene{i+1}' for i in range(num_max_genes)])\n",
        "\n",
        "# Merge the gene columns back with the Drug IDs\n",
        "df_final = pd.concat([df_drugBank_grouped[['Drug IDs']], df_genes], axis=1)\n",
        "\n",
        "# Include the additional columns that we need to track on each drug\n",
        "additional_columns = {\n",
        "    'Drug Name' : '',\n",
        "    'Associated Conditions' : '',\n",
        "    'ATC Class': '',\n",
        "    'MoA': '',\n",
        "    'Drug_Description' : '',\n",
        "    'URL': ''\n",
        "}\n",
        "\n",
        "# Add the additional columns to the DataFrame\n",
        "for col, placeholder in additional_columns.items():\n",
        "  df_final[col] = placeholder\n",
        "\n",
        "# Reorder the columns in the df\n",
        "column_order = ['Drug IDs', 'Drug Name', 'Associated Conditions', 'ATC Class', 'MoA', 'Drug_Description', 'URL'] + [f'gene{i+1}' for i in range(num_max_genes)]\n",
        "\n",
        "df_final = df_final[column_order]\n",
        "df_final.rename(columns={'Drug IDs': 'Drug ID', 'Drug_Description' : 'Drug Description'}, inplace=True) # Rename for the paper.\n",
        "df_final.to_excel('DrugsDataStructure.xlsx', index=False)"
      ],
      "metadata": {
        "id": "NN8nNcXAevqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Preprocess OMIM (morbidmap) dataset.**  \n",
        "Contrain diseases+genes"
      ],
      "metadata": {
        "id": "j28zPe8Q4ykB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_disease_name(disease_name):\n",
        "      # Extract the text inside [] or {}\n",
        "    match = re.search(r'[\\{\\[]([^}\\]]+)[\\}\\]]', disease_name)\n",
        "    if match:\n",
        "        disease_name = match.group(1)\n",
        "    else:\n",
        "        # If there are no brackets, we just clean up the remaining numbers and commas\n",
        "        disease_name = re.sub(r', \\d+$', '', disease_name)\n",
        "\n",
        "    # Extract text up to a number in parenthesis like (1), (2), etc.\n",
        "    # This number explain which way the disease-gene interaction discover.\n",
        "    disease_name = re.sub(r'\\s+\\(\\d+\\)', '', disease_name)\n",
        "    # Remove all '?' characters\n",
        "    disease_name = disease_name.replace('?', '')\n",
        "    # Remove the unique ID numbers.\n",
        "    disease_name = re.sub(r'\\s+\\d{3,}$', '', disease_name)\n",
        "    # Remove commas and extra spaces from the new string\n",
        "    disease_name = disease_name.replace(\",\", \"\")\n",
        "    disease_name = ' '.join(disease_name.split())\n",
        "\n",
        "    return disease_name"
      ],
      "metadata": {
        "id": "OvxxkqEpqeQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "omim_dataset_path = \"morbidmap.txt\"\n",
        "\n",
        "# Convert the dataset from txt to csv file\n",
        "df_omim = pd.read_csv(omim_dataset_path, sep='\\t', comment='#')\n",
        "\n",
        "# Set the columns name\n",
        "df_omim.columns = [\"Disease\",\"Gene\",\"MIM Number\",\"Cyto Location\"]\n",
        "\n",
        "# Keep only the disease and the genes that they are associated with.\n",
        "df_omim = df_omim[['Disease', 'Gene']]\n",
        "\n",
        "# Process the data\n",
        "explode_data = []\n",
        "for index, row in df_omim.iterrows():\n",
        "    disease = row['Disease']\n",
        "    disease = preprocess_disease_name(disease)\n",
        "    genes = row['Gene'].split(',')\n",
        "\n",
        "    for gene in genes:\n",
        "        # In the data\n",
        "        gene = gene.strip().upper()  # Remove white spaces and convert gene to uppercase\n",
        "        explode_data.append({'Disease': disease, 'Gene': gene})\n",
        "\n",
        "# Create a new DataFrame from the array\n",
        "df_explode_omim = pd.DataFrame(explode_data)\n",
        "\n",
        "# Drop rows where 'Gene Symbole' is NaN or empty string\n",
        "df_explode_omim.dropna(subset=['Gene'], inplace=True)\n",
        "df_explode_omim = df_explode_omim[df_explode_omim['Gene'] != '']\n",
        "\n",
        "df_explode_omim.to_csv('processed_omim.csv', index=False)\n",
        "\n",
        "print(df_explode_omim.head())"
      ],
      "metadata": {
        "id": "aIBR2wrx45E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Preprocess Biogrid (PPI) dataset.**  \n",
        " Contrain (PPI - genes+genes)"
      ],
      "metadata": {
        "id": "cEJRnkm34y5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_biogrid = pd.read_csv('BIOGRID-ORGANISM-Homo_sapiens-4.4.217.tab3.txt', sep='\\t', low_memory=False)\n",
        "\n",
        "# Filter the DataFrame to keep rows with 'Homo sapiens' in both organism columns\n",
        "df_filtered_biogrid = df_biogrid[(df_biogrid['Organism Name Interactor A'] == 'Homo sapiens') & (df_biogrid['Organism Name Interactor B'] == 'Homo sapiens')].copy()\n",
        "\n",
        "# Convert genes name to uppercase for consistency\n",
        "df_filtered_biogrid['Official Symbol Interactor A'] = df_filtered_biogrid['Official Symbol Interactor A'].str.upper()\n",
        "df_filtered_biogrid['Official Symbol Interactor B'] = df_filtered_biogrid['Official Symbol Interactor B'].str.upper()\n",
        "\n",
        "# Keep only the Official Symbol of the genes\n",
        "df_filtered_biogrid = df_filtered_biogrid[['Official Symbol Interactor A',\t'Official Symbol Interactor B']]\n",
        "\n",
        "df_filtered_biogrid.to_csv('processed_biogrid.csv', index=False)\n",
        "\n",
        "print(f\"Head of df_filtered_biogrid: \")\n",
        "print(df_filtered_biogrid.head())"
      ],
      "metadata": {
        "id": "84-AYAc745XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Union all the datasets"
      ],
      "metadata": {
        "id": "8tCaAsAp4RaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The file we create this section will be the one we used in the code"
      ],
      "metadata": {
        "id": "piKpEoecGcg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "It is important to use the dataset which we fill manually with labels and the other information of each drug.\n",
        "\"\"\"\n",
        "\n",
        "df_drug = pd.read_excel('SupplementaryFile_DrugAnnotations_4-05-2024.xlsx') # Change the path and name if needed.\n",
        "df_drug.rename(columns={'Drug ID': 'Drug IDs', 'Drug Description': 'Drug_Description'}, inplace=True) # Back again to the original names.\n",
        "# Convert and save as a CSV file\n",
        "df_drug.to_csv('DrugsProcessedData.csv', index=False)\n",
        "df_disease_gene = pd.read_csv('processed_omim.csv')\n",
        "df_gene_gene = pd.read_csv('processed_biogrid.csv')\n",
        "\n",
        "# Extracting drug-gene interactions\n",
        "gene_columns = [col for col in df_drug.columns if 'gene' in col]\n",
        "df_drug_melted = df_drug.melt(id_vars=['Drug IDs', 'MoA', 'ATC Class', 'Drug_Description'],\n",
        "                              value_vars=gene_columns,\n",
        "                              value_name='gene').dropna()\n",
        "\n",
        "df_drug_interactions = df_drug_melted[['Drug IDs', 'gene', 'MoA', 'ATC Class', 'Drug_Description']].copy()\n",
        "df_drug_interactions.rename(columns={\"Drug IDs\": \"Source Name\", \"gene\": \"Target Name\"}, inplace=True)\n",
        "df_drug_interactions['Source Type'] = 'Drug'\n",
        "df_drug_interactions['Target Type'] = 'Gene'\n",
        "df_drug_interactions['Interaction Type'] = 'drug_target'\n",
        "\n",
        "print(f\"Head of drug_target interaction: \")\n",
        "print(df_drug_interactions.head())\n",
        "\n",
        "# Extracting Disease-gene interactions\n",
        "df_disease_interactions = df_disease_gene[['Disease', 'Gene']].copy()\n",
        "df_disease_interactions.rename(columns={\"Disease\": \"Source Name\", \"Gene\": \"Target Name\"}, inplace=True)\n",
        "df_disease_interactions['Source Type'] = 'Disease'\n",
        "df_disease_interactions['Target Type'] = 'Gene'\n",
        "df_disease_interactions['Interaction Type'] = 'association'\n",
        "df_disease_interactions['MoA'] = '-'\n",
        "df_disease_interactions['ATC Class'] = '-'\n",
        "df_disease_interactions['Drug_Description'] = '-'\n",
        "\n",
        "print('\\n'*3)\n",
        "print(f\"Head of association interaction: \")\n",
        "print(df_disease_interactions.head())\n",
        "\n",
        "# Extracting gene-gene interactions\n",
        "df_gene_interactions = df_gene_gene[['Official Symbol Interactor A', 'Official Symbol Interactor B']].copy()\n",
        "df_gene_interactions.rename(columns={\"Official Symbol Interactor A\": \"Source Name\", \"Official Symbol Interactor B\": \"Target Name\"}, inplace=True)\n",
        "df_gene_interactions['Source Type'] = 'Gene'\n",
        "df_gene_interactions['Target Type'] = 'Gene'\n",
        "df_gene_interactions['Interaction Type'] = 'PPI'\n",
        "df_gene_interactions['MoA'] = '-'\n",
        "df_gene_interactions['ATC Class'] = '-'\n",
        "df_gene_interactions['Drug_Description'] = '-'\n",
        "\n",
        "print('\\n'*3)\n",
        "print(f\"Head of PPI interaction: \")\n",
        "print(df_gene_interactions.head())\n",
        "\n",
        "# Merging all the interaction dataframes\n",
        "merged_df = pd.concat([df_drug_interactions, df_disease_interactions, df_gene_interactions], ignore_index=True)\n",
        "\n",
        "merged_df.to_csv(\"comprehensive_dataset.csv.gz\", index=False, compression='gzip')\n"
      ],
      "metadata": {
        "id": "kczHRfrpZBE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guidelines File"
      ],
      "metadata": {
        "id": "Cv687wzgEbFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('DrugsProcessedData.xlsx')\n",
        "\n",
        "# Splitting the ATC Classes and creating a df for each Class\n",
        "dfs_by_atc = {}\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    atc_classes = str(row['ATC Class']).split(',')\n",
        "    for atc in atc_classes:\n",
        "        atc = atc.strip()\n",
        "        if atc not in dfs_by_atc:\n",
        "            dfs_by_atc[atc] = []\n",
        "        dfs_by_atc[atc].append(row)\n",
        "\n",
        "for atc in dfs_by_atc:\n",
        "    dfs_by_atc[atc] = pd.DataFrame(dfs_by_atc[atc])\n",
        "\n",
        "with pd.ExcelWriter('Guidelines_ATC.xlsx') as writer:\n",
        "    for atc, df_atc in tqdm(dfs_by_atc.items(), desc=\"Writing sheets\"):\n",
        "        df_atc.to_excel(writer, sheet_name=atc, index=False)"
      ],
      "metadata": {
        "id": "fGJGN1ofJYKy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}